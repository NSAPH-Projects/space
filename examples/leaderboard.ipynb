{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_method(filename):\n",
    "    options = {\n",
    "        \"results_spatial_plus_final.jsonl\": \"spatial+\",\n",
    "        \"results_spatial_final.jsonl\": \"spatial\",\n",
    "        \"results_GCNN_zero.jsonl\": \"gcnn ZERO\",\n",
    "        \"results_GCNN_1hidden_layer.jsonl\": \"gcnn 1HIDDEN\",\n",
    "        \"results_GCNN_lin.jsonl\": \"gcnn LIN\",\n",
    "        \"results_GCN.jsonl\": \"gcnn ReLU\",\n",
    "        \"results_GM_Lag.jsonl\": \"s2sls\",\n",
    "        \"results_GM_Error.jsonl\": \"glmerr\",\n",
    "        \"results_Ridge.jsonl\": \"ols\",\n",
    "        \"results_dapsm_final.jsonl\": \"dapsm\",\n",
    "    }\n",
    "    return options.get(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meanplusminus(datmean, datstd):\n",
    "    return (\n",
    "        datmean.map(\"{:02.2f}\".format)\n",
    "        + \" Â± {\\small \"\n",
    "        + datstd.map(\"{:02.2f}\".format)\n",
    "        + \"}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_databin(df):\n",
    "    datbin_ate_mean = (\n",
    "        df[df[\"treatment_type\"] == \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"ate_se\"]\n",
    "        .mean()\n",
    "    )\n",
    "    datbin_ate_std = (\n",
    "        df[df[\"treatment_type\"] == \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"ate_se\"]\n",
    "        .std()\n",
    "    )\n",
    "    datbin_ate = get_meanplusminus(datbin_ate_mean, datbin_ate_std)\n",
    "    datbin_pehe_mean = (\n",
    "        df[df[\"treatment_type\"] == \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"pehe_av\"]\n",
    "        .mean()\n",
    "    )\n",
    "    datbin_pehe_std = (\n",
    "        df[df[\"treatment_type\"] == \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"pehe_av\"]\n",
    "        .std()\n",
    "    )\n",
    "    datbin_pehe = get_meanplusminus(datbin_pehe_mean, datbin_pehe_std)\n",
    "    datbin = pd.concat([datbin_ate, datbin_pehe], axis=1)\n",
    "    return datbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datcon(df):\n",
    "    datcon_erf_mean = (\n",
    "        df[df[\"treatment_type\"] != \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"erf_av\"]\n",
    "        .mean()\n",
    "    )\n",
    "    datcon_erf_std = (\n",
    "        df[df[\"treatment_type\"] != \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"erf_av\"]\n",
    "        .std()\n",
    "    )\n",
    "    datcon_erf = get_meanplusminus(datcon_erf_mean, datcon_erf_std)\n",
    "    datcon_pehe_mean = (\n",
    "        df[df[\"treatment_type\"] != \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"pehe_av\"]\n",
    "        .mean()\n",
    "    )\n",
    "    datcon_pehe_std = (\n",
    "        df[df[\"treatment_type\"] != \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"pehe_av\"]\n",
    "        .std()\n",
    "    )\n",
    "    datcon_pehe = get_meanplusminus(datcon_pehe_mean, datcon_pehe_std)\n",
    "    datcon = pd.concat([datcon_erf, datcon_pehe], axis=1)\n",
    "    return datcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dapsm(df):\n",
    "    datbin_ate_mean = (\n",
    "        df[df[\"treatment_type\"] == \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"ate_se\"]\n",
    "        .mean()\n",
    "    )\n",
    "    datbin_ate_std = (\n",
    "        df[df[\"treatment_type\"] == \"binary\"]\n",
    "        .groupby([\"smoothness_binned\", \"confounding_binned\"])[\"ate_se\"]\n",
    "        .std()\n",
    "    )\n",
    "    datbin_ate = get_meanplusminus(datbin_ate_mean, datbin_ate_std)\n",
    "    return datbin_ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"results\"\n",
    "\n",
    "files_list = []\n",
    "# Iterate over all the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # If the filename starts with \"results_\"\n",
    "    if filename.startswith(\"results_\"):\n",
    "        # Construct the full file path\n",
    "        files_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_list(value):\n",
    "    if isinstance(value, list):\n",
    "        return np.mean(value)\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results_GCNN_1hidden_layer.jsonl',\n",
       " 'results_GCN.jsonl',\n",
       " 'results_GCN_hidden_new.jsonl',\n",
       " 'results_GCN_first_MT.jsonl',\n",
       " 'results_GCN_relu_16h.jsonl',\n",
       " 'results_GCNN_lin.jsonl',\n",
       " 'results_GCNN_zero.jsonl']"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: results_GCNN_1hidden_layer.jsonl\n",
      "Filename: results_GCN.jsonl\n",
      "Filename: results_GCN_hidden_new.jsonl\n",
      "Filename: results_GCN_first_MT.jsonl\n",
      "Filename: results_GCN_relu_16h.jsonl\n",
      "Filename: results_GCNN_lin.jsonl\n",
      "Filename: results_GCNN_zero.jsonl\n"
     ]
    }
   ],
   "source": [
    "tlb_list = []\n",
    "\n",
    "for filename in files_list:\n",
    "    print(f\"Filename: {filename}\")\n",
    "    with jsonlines.open(directory_path + \"/\" + filename) as reader:\n",
    "        data = [obj for obj in reader]\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"treatment_type\"] = np.where(\n",
    "        df[\"envname\"].str.contains(\"disc\"), \"binary\", \"continuous\"\n",
    "    )\n",
    "    # df[\"smoothness_binned\"] = pd.qcut(df[\"smoothness\"], q=2, labels=[\"low\", \"high\"])\n",
    "    # df[\"confounding_binned\"] = pd.qcut(df[\"confounding\"], q=2, labels=[\"low\", \"high\"])\n",
    "\n",
    "    # Use pd.cut to create the bins\n",
    "    df[\"smoothness_binned\"] = pd.cut(\n",
    "        df[\"smoothness\"], bins=[-np.inf, 0.5, np.inf], labels=[\"low\", \"high\"]\n",
    "    )\n",
    "    df[\"confounding_binned\"] = pd.cut(\n",
    "        df[\"confounding\"], bins=[-np.inf, 0.025, np.inf], labels=[\"low\", \"high\"]\n",
    "    )\n",
    "\n",
    "    df[\"ate_se\"] = df[\"ate_se\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "    df[\"ate_se\"] = np.sqrt(df[\"ate_se\"])  # df[\"\"] * 100\n",
    "    if filename == \"results_dapsm_final.jsonl\":\n",
    "        dat = get_dapsm(df).to_frame()\n",
    "        dat[\"pehe_bin\"] = \"n/a\"\n",
    "        dat[\"erf_av\"] = \"n/a\"\n",
    "        dat[\"pehe_con\"] = \"n/a\"\n",
    "    elif filename == \"results_GCN_fin.jsonl\":\n",
    "        continue\n",
    "    else:\n",
    "        df[\"pehe_av\"] = np.sqrt(df[\"pehe_av\"])  # df[\"\"] * 100\n",
    "        df[\"erf_av\"] = np.sqrt(df[\"erf_av\"])  # * 100  df[\"\"]\n",
    "\n",
    "        datbin = get_databin(df).rename(columns={\"pehe_av\": \"pehe_bin\"})\n",
    "        datcon = get_datcon(df).rename(columns={\"pehe_av\": \"pehe_con\"})\n",
    "        dat = pd.concat([datbin, datcon], axis=1)\n",
    "\n",
    "    method = process_method(filename)\n",
    "    dat[\"method\"] = method\n",
    "    dat.set_index(\"method\", append=True)\n",
    "    tlb_list.append(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = (\n",
    "    pd.concat(tlb_list)\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\"smoothness_binned\": \"smoothness\", \"confounding_binned\": \"confounding\"}\n",
    "    )\n",
    "    .groupby(by=[\"smoothness\", \"confounding\", \"method\"])\n",
    "    .first()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ate_se</th>\n",
       "      <th>pehe_bin</th>\n",
       "      <th>erf_av</th>\n",
       "      <th>pehe_con</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness</th>\n",
       "      <th>confounding</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">low</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">low</th>\n",
       "      <th>gcnn 1HIDDEN</th>\n",
       "      <td>0.13 Â± {r'\\small0.09}</td>\n",
       "      <td>0.41 Â± {r'\\small0.11}</td>\n",
       "      <td>1.27 Â± {r'\\small1.21}</td>\n",
       "      <td>1.59 Â± {r'\\small1.19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn LIN</th>\n",
       "      <td>0.06 Â± {r'\\small0.05}</td>\n",
       "      <td>0.46 Â± {r'\\small0.13}</td>\n",
       "      <td>1.12 Â± {r'\\small1.17}</td>\n",
       "      <td>1.75 Â± {r'\\small1.12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ReLU</th>\n",
       "      <td>0.08 Â± {r'\\small0.06}</td>\n",
       "      <td>0.29 Â± {r'\\small0.07}</td>\n",
       "      <td>0.57 Â± {r'\\small0.55}</td>\n",
       "      <td>0.75 Â± {r'\\small0.54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ZERO</th>\n",
       "      <td>0.15 Â± {r'\\small0.10}</td>\n",
       "      <td>0.51 Â± {r'\\small0.16}</td>\n",
       "      <td>1.20 Â± {r'\\small1.20}</td>\n",
       "      <td>1.69 Â± {r'\\small1.18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">high</th>\n",
       "      <th>gcnn 1HIDDEN</th>\n",
       "      <td>0.10 Â± {r'\\small0.08}</td>\n",
       "      <td>0.34 Â± {r'\\small0.11}</td>\n",
       "      <td>0.97 Â± {r'\\small0.74}</td>\n",
       "      <td>1.19 Â± {r'\\small0.69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn LIN</th>\n",
       "      <td>0.06 Â± {r'\\small0.04}</td>\n",
       "      <td>0.42 Â± {r'\\small0.12}</td>\n",
       "      <td>0.69 Â± {r'\\small0.57}</td>\n",
       "      <td>1.20 Â± {r'\\small0.52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ReLU</th>\n",
       "      <td>0.06 Â± {r'\\small0.04}</td>\n",
       "      <td>0.24 Â± {r'\\small0.07}</td>\n",
       "      <td>0.55 Â± {r'\\small0.37}</td>\n",
       "      <td>0.67 Â± {r'\\small0.36}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ZERO</th>\n",
       "      <td>0.09 Â± {r'\\small0.10}</td>\n",
       "      <td>0.43 Â± {r'\\small0.20}</td>\n",
       "      <td>1.21 Â± {r'\\small0.83}</td>\n",
       "      <td>1.44 Â± {r'\\small0.79}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">high</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">low</th>\n",
       "      <th>gcnn 1HIDDEN</th>\n",
       "      <td>0.09 Â± {r'\\small0.08}</td>\n",
       "      <td>0.38 Â± {r'\\small0.10}</td>\n",
       "      <td>1.05 Â± {r'\\small1.00}</td>\n",
       "      <td>1.38 Â± {r'\\small0.97}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn LIN</th>\n",
       "      <td>0.06 Â± {r'\\small0.05}</td>\n",
       "      <td>0.47 Â± {r'\\small0.12}</td>\n",
       "      <td>0.84 Â± {r'\\small0.83}</td>\n",
       "      <td>1.49 Â± {r'\\small0.83}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ReLU</th>\n",
       "      <td>0.05 Â± {r'\\small0.04}</td>\n",
       "      <td>0.25 Â± {r'\\small0.06}</td>\n",
       "      <td>0.51 Â± {r'\\small0.52}</td>\n",
       "      <td>0.73 Â± {r'\\small0.50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ZERO</th>\n",
       "      <td>0.13 Â± {r'\\small0.11}</td>\n",
       "      <td>0.48 Â± {r'\\small0.16}</td>\n",
       "      <td>1.29 Â± {r'\\small1.37}</td>\n",
       "      <td>1.78 Â± {r'\\small1.33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">high</th>\n",
       "      <th>gcnn 1HIDDEN</th>\n",
       "      <td>0.11 Â± {r'\\small0.09}</td>\n",
       "      <td>0.32 Â± {r'\\small0.12}</td>\n",
       "      <td>0.89 Â± {r'\\small0.95}</td>\n",
       "      <td>1.19 Â± {r'\\small0.91}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn LIN</th>\n",
       "      <td>0.07 Â± {r'\\small0.05}</td>\n",
       "      <td>0.41 Â± {r'\\small0.13}</td>\n",
       "      <td>1.21 Â± {r'\\small1.01}</td>\n",
       "      <td>1.80 Â± {r'\\small0.96}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ReLU</th>\n",
       "      <td>0.08 Â± {r'\\small0.05}</td>\n",
       "      <td>0.25 Â± {r'\\small0.07}</td>\n",
       "      <td>0.50 Â± {r'\\small0.46}</td>\n",
       "      <td>0.72 Â± {r'\\small0.41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcnn ZERO</th>\n",
       "      <td>0.10 Â± {r'\\small0.09}</td>\n",
       "      <td>0.42 Â± {r'\\small0.20}</td>\n",
       "      <td>1.02 Â± {r'\\small0.83}</td>\n",
       "      <td>1.41 Â± {r'\\small0.82}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ate_se  \\\n",
       "smoothness confounding method                                \n",
       "low        low         gcnn 1HIDDEN  0.13 Â± {r'\\small0.09}   \n",
       "                       gcnn LIN      0.06 Â± {r'\\small0.05}   \n",
       "                       gcnn ReLU     0.08 Â± {r'\\small0.06}   \n",
       "                       gcnn ZERO     0.15 Â± {r'\\small0.10}   \n",
       "           high        gcnn 1HIDDEN  0.10 Â± {r'\\small0.08}   \n",
       "                       gcnn LIN      0.06 Â± {r'\\small0.04}   \n",
       "                       gcnn ReLU     0.06 Â± {r'\\small0.04}   \n",
       "                       gcnn ZERO     0.09 Â± {r'\\small0.10}   \n",
       "high       low         gcnn 1HIDDEN  0.09 Â± {r'\\small0.08}   \n",
       "                       gcnn LIN      0.06 Â± {r'\\small0.05}   \n",
       "                       gcnn ReLU     0.05 Â± {r'\\small0.04}   \n",
       "                       gcnn ZERO     0.13 Â± {r'\\small0.11}   \n",
       "           high        gcnn 1HIDDEN  0.11 Â± {r'\\small0.09}   \n",
       "                       gcnn LIN      0.07 Â± {r'\\small0.05}   \n",
       "                       gcnn ReLU     0.08 Â± {r'\\small0.05}   \n",
       "                       gcnn ZERO     0.10 Â± {r'\\small0.09}   \n",
       "\n",
       "                                                  pehe_bin  \\\n",
       "smoothness confounding method                                \n",
       "low        low         gcnn 1HIDDEN  0.41 Â± {r'\\small0.11}   \n",
       "                       gcnn LIN      0.46 Â± {r'\\small0.13}   \n",
       "                       gcnn ReLU     0.29 Â± {r'\\small0.07}   \n",
       "                       gcnn ZERO     0.51 Â± {r'\\small0.16}   \n",
       "           high        gcnn 1HIDDEN  0.34 Â± {r'\\small0.11}   \n",
       "                       gcnn LIN      0.42 Â± {r'\\small0.12}   \n",
       "                       gcnn ReLU     0.24 Â± {r'\\small0.07}   \n",
       "                       gcnn ZERO     0.43 Â± {r'\\small0.20}   \n",
       "high       low         gcnn 1HIDDEN  0.38 Â± {r'\\small0.10}   \n",
       "                       gcnn LIN      0.47 Â± {r'\\small0.12}   \n",
       "                       gcnn ReLU     0.25 Â± {r'\\small0.06}   \n",
       "                       gcnn ZERO     0.48 Â± {r'\\small0.16}   \n",
       "           high        gcnn 1HIDDEN  0.32 Â± {r'\\small0.12}   \n",
       "                       gcnn LIN      0.41 Â± {r'\\small0.13}   \n",
       "                       gcnn ReLU     0.25 Â± {r'\\small0.07}   \n",
       "                       gcnn ZERO     0.42 Â± {r'\\small0.20}   \n",
       "\n",
       "                                                    erf_av  \\\n",
       "smoothness confounding method                                \n",
       "low        low         gcnn 1HIDDEN  1.27 Â± {r'\\small1.21}   \n",
       "                       gcnn LIN      1.12 Â± {r'\\small1.17}   \n",
       "                       gcnn ReLU     0.57 Â± {r'\\small0.55}   \n",
       "                       gcnn ZERO     1.20 Â± {r'\\small1.20}   \n",
       "           high        gcnn 1HIDDEN  0.97 Â± {r'\\small0.74}   \n",
       "                       gcnn LIN      0.69 Â± {r'\\small0.57}   \n",
       "                       gcnn ReLU     0.55 Â± {r'\\small0.37}   \n",
       "                       gcnn ZERO     1.21 Â± {r'\\small0.83}   \n",
       "high       low         gcnn 1HIDDEN  1.05 Â± {r'\\small1.00}   \n",
       "                       gcnn LIN      0.84 Â± {r'\\small0.83}   \n",
       "                       gcnn ReLU     0.51 Â± {r'\\small0.52}   \n",
       "                       gcnn ZERO     1.29 Â± {r'\\small1.37}   \n",
       "           high        gcnn 1HIDDEN  0.89 Â± {r'\\small0.95}   \n",
       "                       gcnn LIN      1.21 Â± {r'\\small1.01}   \n",
       "                       gcnn ReLU     0.50 Â± {r'\\small0.46}   \n",
       "                       gcnn ZERO     1.02 Â± {r'\\small0.83}   \n",
       "\n",
       "                                                  pehe_con  \n",
       "smoothness confounding method                               \n",
       "low        low         gcnn 1HIDDEN  1.59 Â± {r'\\small1.19}  \n",
       "                       gcnn LIN      1.75 Â± {r'\\small1.12}  \n",
       "                       gcnn ReLU     0.75 Â± {r'\\small0.54}  \n",
       "                       gcnn ZERO     1.69 Â± {r'\\small1.18}  \n",
       "           high        gcnn 1HIDDEN  1.19 Â± {r'\\small0.69}  \n",
       "                       gcnn LIN      1.20 Â± {r'\\small0.52}  \n",
       "                       gcnn ReLU     0.67 Â± {r'\\small0.36}  \n",
       "                       gcnn ZERO     1.44 Â± {r'\\small0.79}  \n",
       "high       low         gcnn 1HIDDEN  1.38 Â± {r'\\small0.97}  \n",
       "                       gcnn LIN      1.49 Â± {r'\\small0.83}  \n",
       "                       gcnn ReLU     0.73 Â± {r'\\small0.50}  \n",
       "                       gcnn ZERO     1.78 Â± {r'\\small1.33}  \n",
       "           high        gcnn 1HIDDEN  1.19 Â± {r'\\small0.91}  \n",
       "                       gcnn LIN      1.80 Â± {r'\\small0.96}  \n",
       "                       gcnn ReLU     0.72 Â± {r'\\small0.41}  \n",
       "                       gcnn ZERO     1.41 Â± {r'\\small0.82}  "
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/vlxgm9n10bz569rffzmcc5dc0000gn/T/ipykernel_36057/2999632155.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  fin.to_latex(\n"
     ]
    }
   ],
   "source": [
    "with open(\"leaderboards.txt\", \"w\") as f:\n",
    "    f.write(\n",
    "        fin.to_latex(\n",
    "            index=True,\n",
    "            escape=False,\n",
    "            formatters={\"name\": str.upper},\n",
    "            float_format=\"{:.3f}\".format,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
